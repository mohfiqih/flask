# def require_api_key(api_key_header):
#     def decorator(func):
#         @wraps(func)
#         def wrapper(*args, **kwargs):
#             api_key = request.headers.get(api_key_header)

#             # Ganti dengan API key yang valid
#             valid_api_key = 'My_c4pTonE_PROJECT'

#             if api_key != valid_api_key:
#                 return jsonify({'message': 'API key tidak valid.'}), 401

#             return func(*args, **kwargs)

#         return wrapper

#     return decorator

# @app.route('/protected', methods=['GET'])
# @require_api_key('API-Key')
# def protected_endpoint():
#     return jsonify({'message': 'Endpoint dilindungi dengan API key.'})

# def require_api_key(func):
#     @wraps(func)
#     def decorated_function(*args, **kwargs):
#         api_key = request.headers.get('API-Key')

#         if api_key != API_KEY:
#             return jsonify({'message': 'API key tidak valid.'}), 401

#         return func(*args, **kwargs)

#     return decorated_function

################################ Register #####################################
# def gen_frames():
#     # Load the model
#     model = load_model("model/image/keras_model.h5", compile=False)

#     # Load the labels
#     class_names = open("model/image/labels.txt", "r").readlines()

#     # Initialize the webcam stream
#     stream_url = "http://10.134.44.206:8080/video"
#     # stream_url = "video/vid_fiqih.mp4"
#     camera = cv2.VideoCapture(stream_url)

#     # Load the face cascade
#     face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')
    
#     while True:
#         # Read the next frame from the stream
#         ret, frame = camera.read()

#         # Check if the frame is valid
#         if not ret:
#             print("Failed to retrieve frame from the stream.")
#             break

#         # Resize the frame to half its size
#         width = int(frame.shape[1] * 0.5)
#         height = int(frame.shape[0] * 0.5)
#         resized_frame = cv2.resize(frame, (width, height), interpolation=cv2.INTER_AREA)

#         # Convert the frame to grayscale
#         gray = cv2.cvtColor(resized_frame, cv2.COLOR_BGR2GRAY)

#         # Detect faces in the frame
#         faces = face_cascade.detectMultiScale(gray, scaleFactor=1.1, minNeighbors=5, minSize=(30, 30))

#         for (x, y, w, h) in faces:
#             # Extract the face region and resize it to (224, 224)
#             face = resized_frame[y:y+h, x:x+w]
#             resized_face = cv2.resize(face, (224, 224), interpolation=cv2.INTER_AREA)

#             # Make the resized face a numpy array and reshape it to the model's input shape
#             image = np.asarray(resized_face, dtype=np.float32).reshape(1, 224, 224, 3)

#             # Normalize the image array
#             image = (image / 127.5) - 1

#             # Predict the model
#             prediction = model.predict(image)
#             index = np.argmax(prediction)
#             class_name = class_names[index]
#             confidence_score = prediction[0][index]

#             # Draw the bounding box around the face
#             cv2.rectangle(frame, (int(x*2), int(y*2)), (int((x+w)*2), int((y+h)*2)), (0, 255, 0), 2)

#             # Display the label near the bounding box
#             label = f"{class_name[2:]}: {np.round(confidence_score * 100)}%"
#             cv2.putText(frame, label, (int(x*2), int(y*2)-10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), 2)

#         # Encode the frame as JPEG
#         ret, buffer = cv2.imencode('.jpg', frame)
        
#         # Convert the frame to bytes
#         frame_bytes = buffer.tobytes()
        
#         # Yield the frame in the response
#         yield (b'--frame\r\n'
#                 b'Content-Type: image/jpeg\r\n\r\n' + frame_bytes + b'\r\n')




# @app.route('/webview/grafik')
# def grafik_gender():
#     process = subprocess.Popen(['streamlit', 'run', '--server.address',
#                                '172.20.10.2', 'grafik/streamlit.py'], stdout=subprocess.PIPE)
#     return Response(iter(process.stdout.readline, b''), mimetype='text/plain')


# @app.route('/webview/analisis')
# def analisis():
#     process = subprocess.Popen(['streamlit', 'run', '--server.address',
#                                '172.20.10.2', 'grafik/total.py'], stdout=subprocess.PIPE)
#     return Response(iter(process.stdout.readline, b''), mimetype='text/plain')

# Web View
# import mysql.connector

# conn = mysql.connector.connect(
#     host="localhost",
#     user="root",
#     password="",
#     database="web_service"
# )

# cur = conn.cursor()
# # ----------------- Gender ------------------ #
# query = "SELECT * FROM gender"
# df = pd.read_sql_query(query, conn)

@app.route('/grafik-jeniskelamin')
def get_data():
    gender_counts = db.session.query(Gender.jenis_kelamin, db.func.count(Gender.jenis_kelamin)).group_by(Gender.jenis_kelamin).all()
    data = {gender: count for gender, count in gender_counts}
    return jsonify(data)
    # gender_counts = df['jenis_kelamin'].value_counts()
    # data = gender_counts.to_dict()
    # return jsonify(data)

@app.route('/grafik-rentangumur')
def get_rentang():
    rentang_counts = db.session.query(Gender.rentang_umur, db.func.count(Gender.rentang_umur)).group_by(Gender.rentang_umur).all()
    rentang = {rentang: count for rentang, count in rentang_counts}
    return jsonify(rentang)
    # rentang_counts = df['rentang_umur'].value_counts()
    # rentang = rentang_counts.to_dict()
    # return jsonify(rentang)

@app.route('/grafik-label')
def get_label():
    label_counts = db.session.query(Gender.label, db.func.count(Gender.label)).group_by(Gender.label).all()
    label = {label: count for label, count in label_counts}
    return jsonify(label)
    # label_counts = df['label'].value_counts()
    # label = label_counts.to_dict()
    # return jsonify(label)

# @app.route('/webview', methods=['GET'])
# def webview():
#     return render_template('webview.html')